https://openreview.net/pdf?id=ZPa2SyGcbwh

特徴に依存するラベルノイズを用いた学習. 
A PROGRESSIVE APPROACH Anonymous authors 
二重盲検レビュー中の論文 

ABSTRACT 
ラベルノイズは実世界の大規模データセットで頻繁に観察される。
ラベルノイズは様々な理由で導入され，不均質で特徴に依存している．ノイズの多いラベルを扱う既存のアプローチの多くは、理想的な特徴に依存しないノイズを想定しているか、理論的に保証されていないヒューリスティックな手法のままであるかの2つのカテゴリーに分類される。
この論文では、一般的に使用されているi.d.ラベルノイズよりもはるかに一般的で、幅広いノイズパターンを網羅している新しい特徴依存ラベルノイズのファミリーを対象とすることを提案する。
この一般的なノイズ群に焦点を当て、ラベルを反復的に補正し、モデルを改良するプログレッシブラベル補正アルゴリズムを提案する。
広範囲の（未知の）ノイズパターンに対して、この戦略で訓練された分類器がベイズ分類器と一致するように収束することを理論的に保証する。
実験では、我々の手法はSOTAのベースラインよりも優れており、様々なノイズタイプとレベルにロバストです。

INTRODUCTION
訓練集合ラベルのノイズへの対処は、教師付き学習における重要な問題である。
大規模データ収集では、データ/クラスの本質的な曖昧性や人間/自動アノテータのミスにより、データの誤ったアノテーションは避けられない(Yan et al., 2014; Veit et al., 2017)。
したがって、ラベルノイズに耐性のある手法を開発することは、実生活でのアプリケーションにおいて非常に重要である。
古典的なアプローチは、ラベルノイズ、すなわちラベルの破損が独立して同一的に分布しており、したがって特徴に依存しないという、かなり単純なi.d.の仮定を取っています。
この仮定に基づく方法は、ノイズパターンを明示的に推定するか（Reed et al. 2014; Patrini et al. 2017; Dan et al. 2019; Xu et al. 2019）、または余分な正則化／損失項を導入するか（Natarajan et al. 2013; Van Rooyen et al. 2015; Xiao et al. 2015; Zhang & Sabuncu, 2018; Ma et al. 2018; Arazo et al. 2019; Shen & Sanghavi, 2019）のいずれかである。
いくつかの結果は、一般的に使用されている損失が、そのようなI.I.D.ラベルノイズに対して自然にロバストであることを証明している(Manwani & Sastry, 2013; Ghosh et al. 2015; Gao et al. 2016; Ghosh et al. 2017; Charoenphakdee et al. 2019; Hu et al. 2020)。
これらの方法は理論的には保証されていますが、通常、ノイズに関する非現実的なI.I.D.の仮定のために、実際には期待されたほどの性能を発揮しません。
これは、ラベルノイズが不均一で特徴に依存しているためと考えられます。
本質的に曖昧な外観を持つ猫は、犬と誤認される可能性が高くなります。
また、照明が悪い場合や閉塞感が強い場合には、重要な視覚的手がかりが知覚できないため、誤ってラベル付けされる可能性があります。
現実世界の課題に対処するためには、より一般的な形式のラベルノイズに対抗する方法が非常に必要です。
不均一なラベルノイズに適応するために、最新の（SOTA）手法はしばしばデータ再校正戦略に頼っています。
彼らは、信頼できるデータまたは正しいデータラベルを段階的に特定し、これらのデータを用いて訓練を行う（田中ら、2018; Wangら、2018; Jiangら、2018; Liら、2019）。
モデルは、より多くのクリーンデータが収集されるか、またはより多くのラベルが修正されるにつれて徐々に改善され、最終的には高精度のモデルに収束する。
これらのデータ再校正法は、ディープニューラルネットの学習能力を最大限に活用し、実際には優れた性能を達成している。
しかし、その根本的なメカニズムは未だに謎に包まれている。
このカテゴリの手法では、なぜモデルが理想的なものに収束するのかについて理論的な洞察を提供することができません。
結果として、これらの手法は、データ収集のペースや基準などのハイパーパラメタを慎重に調整する必要があり、一般化が非常に困難である。

本論文では、特徴に依存する不均質なラベルノイズを対象とした新しい原理に基づいた手法を提案する。
これまでの手法とは異なり、我々は多項式マージン減少(PMD)ラベルノイズと呼ばれる、より一般的なノイズ群を対象としている。
このノイズ群では、真の決定境界から遠く離れたデータを除いて、任意のノイズレベルを許容します。
これは実世界のシナリオと一致しています。
決定境界に近いデータは区別が難しく、ラベル付けが誤って行われる可能性が高くなります。
一方、決定境界から遠く離れたデータは、その真のクラスの典型的な例であり、合理的に制限されたノイズレベルを持つべきです。
この新しいPMDノイズ群を仮定して、我々は理論的に保証されたデータ再校正アルゴリズムを提案し、ノイズの多い分類器の信頼度に基づいてラベルを徐々に修正する。
まず、信頼度の高いデータポイントからスタートし、そのデータのラベルをノイズ分類器の予測値を用いて修正する。
次に、クレンジングされたラベルを用いてモデルを改良する。
収束するまでラベル補正とモデル改善を交互に行います。

図1を参照してください。
我々の主な定理は、理論に基づいて各反復でラベル補正の基準を選択することで、ラベルの純度の向上が保証されることを示している。
このようにして、モデルは十分な速度で反復して改善され、最終的にはベイズ最適分類器と一致することが保証される。
理論的な強さに加えて、我々の手法が実際にどのような力を持っているかを実証する。
我々の手法は、様々な合成ノイズパターンを持つCIFAR-10/100において、他の手法よりも優れた性能を示した。
また，未知のノイズパターンを持つ実世界のデータセットにおいて，SOTAに対して我々の手法を評価した．我々の知る限りでは、我々の手法は、理論的に理想的なモデルに収束することが保証された最初のデータ再校正手法である。
PMDノイズファミリーは、不均一で特徴に依存するノイズの広いスペクトルを含み、実世界のシナリオをよりよく近似している。
また、ラベルノイズの研究のための新しい理論的設定を提供します。


図 1：合成データを用いたアルゴリズムの説明図。
(a) ラベルがきれいなガウスブロブ（η ∗ (x)）。
(b) ラベルが破損しているデータ。
(c) 最終的に修正されたデータ。
黒い点はラベルがきれいなデータ。
赤い点はノイズの多いデータ。
補正されていない点は決定境界に近い。
我々のアルゴリズムは、ノイズの大部分をノイズの多い分類器の信頼度のみで補正している。
(d) ラベル補正後のデータセット。
(e)-(h) 異なる繰り返しでの中間結果を示しています。
灰色の領域は、分類器の信頼度が高い領域です。
この領域内のラベルが補正されています。


Related works
固有値ラベルノイズを想定していない研究をレビューする。
Menonら(2018)は(Ghosh et al., 2015)の研究を一般化し、ある条件を満たす損失が自然にインスタンス依存ノイズに抵抗することを示すエレガントな理論的枠組みを提供している。
この方法は、クリーンな事後確率ηに対するより強い仮定で、さらに優れた理論的特性（すなわち、ベイズ整合性）を達成することができる。
実際には、この方法はディープニューラルネットワークには拡張されていない。
Chengら（2020）は、インスタンス依存ラベルノイズに対する能動学習法を提案した。
このアルゴリズムは、慎重に選択されたデータ上でオラクルからクリーンラベルを反復的に問い合わせる。
しかし、このアプローチは、コーシャアノテーションがアクセスできない設定には適用できない。

データ再校正法では、ノイズの多いネットワークの予測を用いて反復的にデータを選択/修正し、モデルを改善する。
田中ら(2018)は、ネットワークが自身の予測と一致するように損失を強制的に導入し、学習中にラベル補正を行った。
Wangら(2018)は、周囲のデータとのラベルの整合性に基づいて、ノイズの多いラベルをアウトライアとして識別した。
Jiangら（2018）は、データムがクリーンかどうかを判断するために、小さなコーシャデータセット上で教師ネットが訓練されるメンターネット戦略を使用した。
その後、各データムに重みを与える学習カリキュラムが学習と推論のために生徒ネットにフィードされる。
(Yu et al., 2019; Han et al., 2018)は、2つの同期ネットワークを訓練した。
2つのネットワークの信頼性と一貫性は、クリーンなデータを選択するために使用されます。
完全性のために、同様の設計の他の方法も参照する（Liら、2017; Vahdat、2017; Veitら、2017; Maら、2018; Thulasidasanら、2019; Arazoら、2019; Shuら、2019; Yi & Wu、2019）。
理論的なガレートについては、Renら(2018)が最適化問題を解くことで各データポイントを反復的に再重み付けするアルゴリズムを提案した。
彼らは訓練の収束を証明したが、モデルが理想的なものに収束することを保証することはできない。
Amidら(2019b)は(Amid et al., 2019a)の研究を一般化し、緩和されたマッチングロスを提案した。
彼らは、最終的なソフトマックス層をこの二温化された一致損失で置き換えると、結果として得られる分類器がベイズ整合的になることを示した。
Zhengら(2020)は、彼らのデータ再校正法の一発保証を証明した。
しかし、モデルの収束は保証されていない。
我々の手法は、良好な振る舞いの分類器への収束が保証された最初のデータ再校正手法である

2 METHOD

まず、Poly-Margin Diminishing (PMD)ラベルノイズのファミリを紹介する。
第2.2節では、我々の主要なアルゴリズムを紹介する。
最後に、第3節でアルゴリズムの正しさを証明する。
表記法と前置き ノイズの設定とアルゴリズムは当然マルチクラスにも一般化しますが、ここでは簡単のために2値分類に焦点を当てます。

特徴空間を X とします。
データ(x, y)は、X × {0, 1}上の分布Dからサンプリングされたものと仮定します。
事後確率η(x) = P[y = 1 | x]と定義する。
τ0,1(x) = P[ye = 1 | y = 0, x]、τ1,0(x) = P[ye = 0 | y = 1, x]をノイズ関数とします。
例えば、あるデータxが真のラベルy = 0の場合、τ0,1(x)の確率で1まで破損する。
 同様に、τ1,0(x)の確率で1から0まで破損する。
 ηe(x) = P[ye = 1 | x]は、特徴xが与えられた場合のye = 1のノイズ性事後確率である。
 η ∗ (x) = I{η(x)≧1 2 }は、(クリーンな)ベイズ最適分類器であり、IAはAが真であれば1に等しく、そうでなければ0である。
最後に、f(x) : X → [0, 1] を分類器のスコアリング関数（本論文ではニューラルネットワークの softmax 出力）とする。

2.1 POLY-MARGIN DIMINISHING NOISE

まず、本論文で扱うノイズ関数τのファミリーを紹介します。
多項式マージン逓減ノイズ(PMDノイズ)の概念を導入する。
これは、η(x)のあるレベル集合内のノイズτのみを上限とし、制限領域外ではτが任意に高くなることを可能にするものである。
この定式化は、特徴に依存しないシナリオをカバーするだけでなく、(Du & Cai, 2015; Menon et al., 2018; Cheng et al., 2020)によって提案されたシナリオを一般化する。
定義1（PMDノイズ）。
τ0,1(x)とτ1,0(x)の組のノイズ関数は、定数t0 ∈(0, 1 2 )、およびc1, c2 > 0が存在する場合、多項式マージン逓減(PMD)である。

ここでは、t0をτの "マージン "と呼ぶことで表記を乱用しています。
PMD条件は、ベイズ分類器がかなり自信を持っている領域において、τの上界が多項式で単調に減少することを必要とするだけであることに注意してください。
領域{x . |η(x) - 1 2 | < t0}では、τ01(x)とτ10(x)を任意に設定することができます。
図2(d)は、上限値(オレンジ色の曲線)とサンプルノイズ関数(青色の曲線)を示しています。
また、このノイズ関数に従った破損データも示しています（赤点は破損ラベル、黒点はクリーンラベル）。

PMDノイズファミリーは、既存のノイズの仮定よりもはるかに一般的です。
例えば、境界整合性ノイズ（BCN）（Du & Cai, 2015; Menonら, 2018）は、データが決定境界から遠ざかるにつれて単調に減少するノイズ関数を想定しています。
図2(c)を参照してください。
このノイズは、(1)単調な上界のみを必要とし、(2)決定境界付近の広いバッファ内で任意のノイズ強度を許容する我々のPMDノイズと比較して、はるかに制限的である。
図２（ｂ）は、従来の特徴に依存しないノイズパターン（Reed et al. 2014; Patrini et al. 2017)は、τ0,1(x)（resp.

図2：異なるノイズ関数の説明図。
(a) 元のデータ。
クリーンラベルを持つガウシアン・ブロブ（クリーンラベルとは、ベイズ分類器の予測値η ∗ (x)のことで、yではない）。
この場合のη（つまりf）の信頼領域は、η（x）が0または1に近いところです。
青と緑の点は2つのクラスを示している。
(b) 一様ラベルノイズ：各点が反転する確率が等しい。
赤い点はラベルが破損しているデータです。
黒い点はラベルが破損していないデータです。
(c) BCNノイズ： η ∗ (x)が確信度になるにつれてノイズレベルは減少していく (d) PMDノイズ： η(x)がある閾値より高いか低い場合にのみ、ノイズレベル(青)は逓減多項式関数によって上界が設定される。
上限は赤線で示しています。


2.2 THE PROGRESSIVE CORRECTION ALGORITHM

我々のアルゴリズムは、ニューラルネットワークを反復的に訓練し、ラベルを補正する。
我々は、元のノイズの多いデータでニューラルネットワーク(NN)を訓練するウォームアップ期間から始めます。
これにより、ノイズのフィッティングを開始する前に合理的なネットワークを達成することができます(Zhang et al., 2017)。
ウォームアップ期間の後、分類器はラベル補正のために使用することができます。
我々は、分類器fが非常に高い信頼性を持つラベルのみを補正する。
直感的には、ノイズの仮定の下では、ノイズの多い分類器fの予測が非常に信頼度が高く、クリーンなベイズ最適分類器ηと一致する "純粋な領域 "が存在するということです。
したがって、ラベル補正はこの純粋領域内でクリーンなラベルを与える。
特に、高い閾値θを選択し、fが異なるラベルをy〜として予測し、その信頼度が閾値｜f(x) - 1/2| > θ以上であれば、ラベルy〜をfの予測に反転させ、ラベルが修正されなくなるまでラベルの修正とネットワークの改善を繰り返す。
次に、しきい値θを少し下げ、下げたしきい値をラベル補正に使用し、それに応じてモデルを改善する。
収束するまでこの処理を続ける。
理論的分析の便宜上、本アルゴリズムでは、連続的に増加する閾値Tを定義し、θ＝1/2-Tとする。
我々のアルゴリズムは、アルゴリズム１に要約される。
第3節では、この反復アルゴリズムが、入力インスタンスの大部分について、クリーンベイズ分類器η ∗ (x)と一致するように収束することを示す。
マルチクラスへの一般化 マルチクラスシナリオでは、ラベルiの分類器の予測確率をfi(x)とする。
f(x) - 1 2項を、最高信頼度fhx (x)とye上の信頼度fye(x)との間のギャップに変更する。
これら2つの信頼度の差の絶対値がある閾値θよりも大きければ, yeをhxに修正する. 実際には、対数の差を用いた方がよりロバストであることがわかります。






