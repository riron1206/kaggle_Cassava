■試すべきこと
- ラベルスムージング
- 勾配クリッピング
- 最後の層のシグモイド+ BinaryCrossentropy
- TTA
- 画像の入力サイズ変えたモデルアンサンブルも有効みたい
- cutmix
- se-resnet50
- SwAV(以前のkaggleデータセットからのラベルなし画像で)

--------------------------------------------------------------
■試したいnotebook

Vit-pytorch
https://www.kaggle.com/szuzhangzhi/vision-transformer-vit-cuda-as-usual

--------------------------------------------------------------

■アンサンブルするモデル
1.元のアスペクト比を使用
2.サイズ変更を使用
3.センタークロップを使用
非常に異なるCVスコアが得られることに気づきました。したがって、これらのモデルをアンサンブルすると役立つ可能性があります。https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/205491

--------------------------------------------------------------
■ディスカッションメモ


cvとLBはほぼ一致
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/198219


# Attension系のモデル紹介
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/203083


同じ画像なのにラベル違う
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/198202


ラベルノイズ多い
cgmとラベル付けされていますが画像には非常に多くの葉があり、健康な葉がいくつか見られる
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/202673


この競合は、データセット内のノイズを推定し、正しいトレーニングパラメータを適用してベイズエラーを取得するようなものらしいテストセットもノイズが多い！！！！要はラベルが間違っているサンプル多い（=trainのノイズラベルを除くのは意味なし）
早期停止やラベルのスムーズ、SVMの適用などの一般的な手法があります
（ケロッピ談）
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/202017


以前のkaggleデータセットからのラベルなし画像を使用したオフライン半教師あり学習（SimCLRv2、SwAV、MoCo）
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/199276


勾配クリッピングも有効なのかも
グラジエントクリッピングはラベルノイズを軽減できますか？ICLR 2020
https://openreview.net/pdf?id=rklB76EKPr


異なるラベルに対応する画像はそれらの間で類似性があり、データセットは画像に誤ったラベルが付けられているという事実を考えると、GroupStratified-Kfoldを使用する方が良いと私は主張
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/201699


過去コンペから自前で精査したキャッサバデータセット
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/200722


サブミットは約15,000枚の画像予測される
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/201473


VIT
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/201601


去年のコンペでは 512*512 se-resnet50 5fold 3TTA
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/200141


モデルのパフォーマンスを改善するために実験する8つの手法
- 最後の層のシグモイド+ BinaryCrossentropy +ラベルの平滑化はsoftmaxよりも優れているはず
- using noisy students weights
- Fmix
- クロスエントロピー損失以外の損失. Focal lossとか
- dropout
- ノイズの多いラベルを処理するときに過去に行ったことは、softmax以降のすべてのデータでトレーニングされたモデルのOOF予測を使用し、softmax値が小さすぎて正しいラベルが得られない画像を削除する
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/202351


ノイズの多いラベルに関する論文
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/202581


前のコンペのベースラインnotebook(pytorch)
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/202485


アプリケーションの観点から、フレーマーは対象のオブジェクトを画像の中央に配置する必要があります。
センタークロップだけを取るか、センターフォーカスアテンションマスクを置くと、結果はもっと良くなるでしょうか？
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/202673


ラベルスムージングは効くがCutMixはうまくいかんらしい
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/202206


ジグソーみたいなデータ水増し
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/202560


画像の入力サイズ変えたモデルアンサンブルも有効みたい
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/200726


SnapMix
新しいデータオーギュメントの方法
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/202627


キャッサバの鉛の病気の解説
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/198143


ディープラーニング+植物病害分類研究論文
https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/199692

--------------------------------------------------------------

画像の過去コンペと同じようにtrainとtestでラベルの分布違うのかなあ
3種(300*300, 460*460, 456*456の画像サイズ違いでモデル作りfeature map多様化させるの有効みたい)
https://speakerdeck.com/hoxomaxwell/kaggle-aptos-2019-at-u-tokyo-med?slide=11

ベンガル語の上位解法
https://st1990.hatenablog.com/entry/2020/03/18/175001


Signateクジラコンペの解法。クラス数不定の分類問題なのでArcFace使ってる
https://www.slideshare.net/ren4yu/humpback-whale-identification-challenge



--------------------------------------------------------------
# https://www.kaggle.com/ababino/cutmix-with-fastai-and-efficientnet
class CutMix(MixUp):
    def __init__(self, alpha=1.): self.distrib = Beta(tensor(alpha), tensor(alpha))
    def before_batch(self):
        lam = self.distrib.sample().squeeze().to(self.x.device)
        shuffle = torch.randperm(self.y.size(0)).to(self.x.device)
        self.yb1 = tuple(L(self.yb).itemgot(shuffle))
        nx_dims = len(self.x.size())
        bs, c, h, w = self.x.shape
        rx, ry = w*self.distrib.sample(), h*self.distrib.sample()
        rw, rh = w*(1-lam).sqrt(), h*(1-lam).sqrt()
        x1 = (rx-rw/2).clamp(min=0).round().to(int)
        x2 = (rx+rw/2).clamp(max=w).round().to(int)
        y1 = (ry-rh/2).clamp(min=0).round().to(int)
        y2 = (ry+rh/2).clamp(max=h).round().to(int)
        self.learn.xb[0][:,:,y1:y2,x1:x2] = self.learn.xb[0][shuffle,:,y1:y2,x1:x2]
        self.lam = 1- float(x2-x1)*(y2-y1)/(h*w)
        
        if not self.stack_y:
            ny_dims = len(self.y.size())
            self.learn.yb = tuple(L(self.yb1,self.yb).map_zip(torch.lerp,weight=unsqueeze(self.lam, n=ny_dims-1)))
            
LB: 0.89
https://www.kaggle.com/dunklerwald/pytorch-efficientnet-with-tta-inference
class EfficientNet(nn.Module):
    def __init__(self, num_classes):
        super(EfficientNet, self).__init__()
        #self.base_model = efficientnet_pytorch.EfficientNet.from_pretrained('efficientnet-b' + str(EFFNET_MODEL))
        self.base_model = timm.create_model(f"tf_efficientnet_b{str(EFFNET_MODEL)}_ns", pretrained=False)
        self.dropout = nn.Dropout(0.2)
        
        self.out = nn.Linear(
            in_features=effnet_output[EFFNET_MODEL], 
            out_features=num_classes, 
            bias=True
        )
        
    def forward(self, image, targets=None):
        batch_size, _, _, _ = image.shape
        
        x = self.base_model.forward_features(image) 
        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)
        out = self.out(self.dropout(x)) 
        
        return out, None, None 


https://www.kaggle.com/dunklerwald/pytorch-efficientnet-with-tta-training
#source: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/173733
class SmoothCrossEntropyLoss(_WeightedLoss):
    def __init__(self, weight=None, reduction='mean', smoothing=SMOOTHING):
        super().__init__(weight=weight, reduction=reduction)
        self.smoothing = smoothing
        self.weight = weight
        self.reduction = reduction

    @staticmethod
    def _smooth_one_hot(targets:torch.Tensor, n_classes:int, smoothing=SMOOTHING):
        assert 0 <= smoothing < 1
        with torch.no_grad():
            targets = torch.empty(size=(targets.size(0), n_classes),
                    device=targets.device) \
                .fill_(smoothing /(n_classes-1)) \
                .scatter_(1, targets.data.unsqueeze(1), 1.-smoothing)
        return targets

    def forward(self, inputs, targets):
        targets = SmoothCrossEntropyLoss._smooth_one_hot(targets, inputs.size(-1),
            self.smoothing)
        lsm = F.log_softmax(inputs, -1)

        if self.weight is not None:
            lsm = lsm * self.weight.unsqueeze(0)

        loss = -(targets * lsm).sum(-1)

        if  self.reduction == 'sum':
            loss = loss.sum()
        elif  self.reduction == 'mean':
            loss = loss.mean()

        return loss


class CustomSchedulerLR:
    def lrfn(self, epoch):      
        if epoch < self.lr_ramp_ep:
            lr = (self.lr_max - self.lr_start) / self.lr_ramp_ep * epoch + self.lr_start           
        elif epoch < self.lr_ramp_ep + self.lr_sus_ep:
            lr = self.lr_max
        else:
            lr = (self.lr_max - self.lr_min) * self.lr_decay**(epoch - self.lr_ramp_ep - self.lr_sus_ep) + self.lr_min

        return lr   

    def __init__(self, optimizer, epoch, batch_size):
        self.lr_start = 0.00005
        self.lr_min = 0.00005
        self.lr_ramp_ep = 5
        self.lr_sus_ep = 0
        self.lr_decay = 0.8  
        self.lr_max = 0.00001 * batch_size
        self.optimizer = optimizer

        lr = self.lrfn(epoch)    
        for param_group in self.optimizer.param_groups:
            param_group['lr'] = lr

    def step(self, epoch):
        lr = self.lrfn(epoch)  
        for param_group in self.optimizer.param_groups:
            param_group['lr'] = lr


LB: 0.89 resnext50_32x4d
# https://www.kaggle.com/manojprabhaakr/leaf-classification-resnext-50-32-4d



------------------------------------------------------------------------

# https://www.kaggle.com/frlemarchand/efficientnet-aug-tf-keras-for-cassava-diseases

def load_image_and_label_from_path(image_path, label):
    img = tf.io.read_file(image_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.cast(img, tf.float32) / 255.0
    return img, label


training_data = tf.data.Dataset.from_tensor_slices((train_df.filepath.values, train_df.label.values))
validation_data = tf.data.Dataset.from_tensor_slices((validation_df.filepath.values, validation_df.label.values))

AUTO = tf.data.experimental.AUTOTUNE

training_ds = (
    training_data
    .map(load_image_and_label_from_path, num_parallel_calls=AUTO)
    .repeat()
    .shuffle(buffer_size=256)
    .batch(BATCH_SIZE)
    .prefetch(buffer_size=AUTO)
)
testing_ds = (
    validation_data
    .map(load_image_and_label_from_path, num_parallel_calls=AUTO)
    .batch(BATCH_SIZE)
    .prefetch(buffer_size=AUTO)
)



import numpy as np
import pandas as pd
from sklearn.model_selection import StratifiedKFold

df = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')

n_splits = 10

skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    
for fold, (trn_idx, val_idx) in enumerate(skf.split(np.arange(df.shape[0]), df.label.values)):
    df.loc[df.iloc[val_idx].index, 'fold'] = fold

df["filepath"] = f"../input/cassava-leaf-disease-classification/train_images/" + df["image_id"]
display(df.head())

train_df = df[df["fold"] == 0]
print('train_df Class distribution per fold.\n', train_df['label'].value_counts())

print()

validation_df = df[df["fold"].isin([7, 8, 9])]
print('validation_df Class distribution per fold.\n', validation_df['label'].value_counts())

TRAINING_FILENAMES = train_df["filepath"]
VALID_FILENAMES = validation_df["filepath"]
NUM_TRAINING_IMAGES = len(TRAINING_FILENAMES)
NUM_VALIDATION_IMAGES = len(VALID_FILENAMES)




        #return {"train_loss": loss, "train_acc": acc}

#    def training_epoch_end(self, training_step_outputs):   
#        avg_loss = torch.stack(
#            [x["train_loss"] for x in training_step_outputs]
#        ).mean()
#        avg_acc = torch.stack(
#            [x["train_acc"] for x in training_step_outputs]
#        ).mean()
#
#        if CFG.wandb_project is not None:
#            self.logger.log_metrics({"avg_loss": avg_loss})
#            self.logger.log_metrics({"avg_acc": avg_acc})
#
#        return {"train_loss": avg_loss, "train_acc": avg_acc}




